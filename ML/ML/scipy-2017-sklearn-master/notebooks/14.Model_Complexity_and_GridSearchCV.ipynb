{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Parameter-selection,-Validation,-and-Testing\" data-toc-modified-id=\"Parameter-selection,-Validation,-and-Testing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Parameter selection, Validation, and Testing</a></div><div class=\"lev2 toc-item\"><a href=\"#Hyperparameters,-Over-fitting,-and-Under-fitting\" data-toc-modified-id=\"Hyperparameters,-Over-fitting,-and-Under-fitting-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Hyperparameters, Over-fitting, and Under-fitting</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.407975\n",
      "n_neighbors: 3, average score: 0.682648\n",
      "n_neighbors: 5, average score: 0.761182\n",
      "n_neighbors: 10, average score: 0.689130\n",
      "n_neighbors: 20, average score: 0.566256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYMnAGGMMlgyMMcYA/w9+wLs1oQ/DewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb13f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train R2\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test R2\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.082540\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.027447\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.020477\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.007301\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.035833\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.004978\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.088547\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.046064\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.131479\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.179301\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.496613\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.345221\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.167224\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.526645\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.659712\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.647630\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.598364\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.594086\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.635288\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.734955\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.113521, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.015507, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.028523, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.111810, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.013768, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.026386, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.104530, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.006081, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.016937, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.106021, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.006941, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.018312, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.111630, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.013600, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.026163, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.091218, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.003332, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.003820, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.005884, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.085210, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.096938, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.009533, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.075570, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.080913, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.088596, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.004979, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.001500, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.093391, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.152842, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.202761, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.471301, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.427908, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.587824, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.479446, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.415053, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.538785, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.111939, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.158537, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.220179, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.593485, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.463550, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.671736, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.690379, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.501699, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.720452, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.768992, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.565031, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.750240, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.588227, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.467457, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.669675, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.643243, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.484253, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.643473, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.731428, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.485186, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.683246, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.811384, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.636854, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.759459, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73665391314\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['params', 'mean_fit_time', 'mean_score_time', 'split0_test_score', 'std_test_score', 'split1_train_score', 'split1_test_score', 'mean_test_score', 'split0_train_score', 'rank_test_score', 'mean_train_score', 'std_score_time', 'split2_test_score', 'std_train_score', 'param_gamma', 'split2_train_score', 'std_fit_time', 'param_C'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-0.009159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>-0.015507</td>\n",
       "      <td>-0.003676</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.043668</td>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-0.051266</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.111810</td>\n",
       "      <td>-0.011967</td>\n",
       "      <td>-0.013768</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>-0.026386</td>\n",
       "      <td>-0.008547</td>\n",
       "      <td>4.714266e-04</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.043756</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>-0.043136</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.104530</td>\n",
       "      <td>-0.004528</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>-0.016937</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>4.714827e-04</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.044285</td>\n",
       "      <td>0.006095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.044380</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.106021</td>\n",
       "      <td>-0.005877</td>\n",
       "      <td>-0.006941</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044482</td>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.051076</td>\n",
       "      <td>-0.007022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.111630</td>\n",
       "      <td>-0.011782</td>\n",
       "      <td>-0.013600</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>-0.026163</td>\n",
       "      <td>-0.008406</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043761</td>\n",
       "      <td>0.004558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.000667         0.000667        -0.053127         -0.009159   0.001   \n",
       "1       0.000667         0.000333        -0.051266         -0.007219   0.001   \n",
       "2       0.000667         0.000333        -0.043136          0.001387   0.001   \n",
       "3       0.001000         0.000000        -0.044380          0.000350   0.001   \n",
       "4       0.001000         0.000000        -0.051076         -0.007022    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.113521           -0.013708          -0.015507   \n",
       "1          -0.111810           -0.011967          -0.013768   \n",
       "2          -0.104530           -0.004528          -0.006081   \n",
       "3          -0.106021           -0.005877          -0.006941   \n",
       "4          -0.111630           -0.011782          -0.013600   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0           -0.003676          -0.028523           -0.010093  4.714827e-04   \n",
       "1           -0.001145          -0.026386           -0.008547  4.714266e-04   \n",
       "2            0.009774          -0.016937           -0.001084  4.714827e-04   \n",
       "3            0.008073          -0.018312           -0.001146  1.123916e-07   \n",
       "4           -0.000878          -0.026163           -0.008406  1.123916e-07   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000471        0.043668         0.004148  \n",
       "1        0.000471        0.043756         0.004517  \n",
       "2        0.000471        0.044285         0.006095  \n",
       "3        0.000000        0.044482         0.005793  \n",
       "4        0.000000        0.043761         0.004558  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.638038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.634268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.590852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.736654\n",
       "15       1           1         0.695497\n",
       "14       1         0.1         0.638038\n",
       "18      10         0.1         0.634268\n",
       "17      10        0.01         0.590852"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.220206, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.218647, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.211455, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.211532, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.218499, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.207958, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.189117, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.169605, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.208235, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-0.121243, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.330136, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.325939, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................ C=1, gamma=0.001, score=-0.124833, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.394478, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.553513, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.607999, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.387956, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.452540, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.556388, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.639613, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'digits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-ad44424fe529>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'neighbors'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m train_scores, test_scores = GridSearchCV(KNeighborsClassifier(), digits.data, digits.target,\n\u001b[0m\u001b[0;32m      5\u001b[0m                                              param_grid=n_neighbors, cv=cv)\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train R2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'digits' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "n_neighbors = {'neighbors': [1, 3, 5, 10, 20, 50]}\n",
    "train_scores, test_scores = GridSearchCV(KNeighborsClassifier(), digits.data, digits.target,\n",
    "                                             param_grid=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train R2\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test R2\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
